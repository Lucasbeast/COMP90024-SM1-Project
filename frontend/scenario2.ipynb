{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a0218d-5821-4812-87be-fe8f2cde9e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import Dash, dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4426bfb-b047-45cb-838e-d117a5d96455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_es(body, index_name):\n",
    "    \"\"\"\n",
    "       Sends a POST request to a specified endpoint to query an Elasticsearch index.\n",
    "   \n",
    "       This function constructs a JSON payload using the provided 'body' and 'index_name',\n",
    "       which represent the query parameters and the name of the Elasticsearch index respectively.\n",
    "       It then sends a POST request to a Flask application handling the '/data-extract' endpoint.\n",
    "       The Flask application is expected to forward this query to an Elasticsearch server.\n",
    "   \n",
    "       Parameters:\n",
    "       - body (dict): The Elasticsearch query in the form of a dictionary.\n",
    "       - index_name (str): The name of the Elasticsearch index to be queried.\n",
    "   \n",
    "       Returns:\n",
    "       - dict: If the request is successful (HTTP 200), returns the JSON response containing the query results.\n",
    "       - str: If the request fails, returns a string message indicating the failure with the HTTP status code.\n",
    "   \n",
    "       Example of 'body':\n",
    "       {\n",
    "           \"query\": {\n",
    "               \"match\": {\n",
    "                   \"text\": \"search term\"\n",
    "               }\n",
    "           }\n",
    "       }\n",
    "       \"\"\"\n",
    "    # route url: /data-extract --method POST\n",
    "    url = f\"http://127.0.0.1:9090/data-extract\"\n",
    "    response = requests.post(url, json={\"body\": body, \"index\": index_name})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Parse the response as JSON\n",
    "    else:\n",
    "        return f\"Failed to fetch data: Status code {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95380c18-ed4a-41ca-8b53-ff07e9764689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1524258746012106753</td>\n",
       "      <td>2022-05-11T05:22:59Z</td>\n",
       "      <td>-34.207857</td>\n",
       "      <td>146.950756</td>\n",
       "      <td>-0.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1524328442337976320</td>\n",
       "      <td>2022-05-11T09:59:55Z</td>\n",
       "      <td>-34.452279</td>\n",
       "      <td>142.290361</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1524337742389256192</td>\n",
       "      <td>2022-05-11T10:36:53Z</td>\n",
       "      <td>-36.070411</td>\n",
       "      <td>144.596631</td>\n",
       "      <td>-0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1524258523672354816</td>\n",
       "      <td>2022-05-11T05:22:06Z</td>\n",
       "      <td>-37.727357</td>\n",
       "      <td>145.508053</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1524353091755069440</td>\n",
       "      <td>2022-05-11T11:37:52Z</td>\n",
       "      <td>-36.818742</td>\n",
       "      <td>145.895791</td>\n",
       "      <td>0.050847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id            created_at   latitude   longitude  sentiment\n",
       "0  1524258746012106753  2022-05-11T05:22:59Z -34.207857  146.950756  -0.081081\n",
       "1  1524328442337976320  2022-05-11T09:59:55Z -34.452279  142.290361   0.050000\n",
       "2  1524337742389256192  2022-05-11T10:36:53Z -36.070411  144.596631  -0.057143\n",
       "3  1524258523672354816  2022-05-11T05:22:06Z -37.727357  145.508053   0.428571\n",
       "4  1524353091755069440  2022-05-11T11:37:52Z -36.818742  145.895791   0.050847"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query twitter data\n",
    "twitter_query = {\n",
    "    \"query\": {\n",
    "        \"range\": {\n",
    "            \"created_at\": {\n",
    "                #mofides here if you want different dates\n",
    "                \"gte\": \"2022-05-11T00:00:00Z\",\n",
    "                \"lte\": \"2022-07-31T23:59:59Z\",\n",
    "                \"format\": \"strict_date_optional_time\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    #modifes if you want different size \n",
    "    \"size\": 1000\n",
    "}\n",
    "\n",
    "index_name = 'twitter'\n",
    "twitter_data = query_es(body=twitter_query, index_name=index_name)\n",
    "extracted_twitter_data = [\n",
    "    {\n",
    "        \"id\": entry[\"_id\"],\n",
    "        \"created_at\": entry[\"_source\"][\"created_at\"],\n",
    "        \"latitude\": entry[\"_source\"][\"geo\"][\"latitude\"],\n",
    "        \"longitude\": entry[\"_source\"][\"geo\"][\"longitude\"],\n",
    "        \"sentiment\": entry[\"_source\"][\"sentiment\"]\n",
    "    }\n",
    "    for entry in twitter_data\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_twitter = pd.DataFrame(extracted_twitter_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc87f896-282f-4397-ad50-0fdb51e0204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id  latitude  longitude  \\\n",
      "0  hb08a48BAp0N_qlVRIya  145.1324 -37.828728   \n",
      "1  hb08a48BAp0N_qlVRIya  145.1324 -37.828728   \n",
      "2  iL08a48BAp0N_qlVV4xG  146.5392 -38.295850   \n",
      "3  iL08a48BAp0N_qlVV4xG  146.5392 -38.295850   \n",
      "4  ir08a48BAp0N_qlVWoxs  146.4828 -38.129670   \n",
      "\n",
      "                                 siteID         siteName parameter_name  \\\n",
      "0  77062cb7-3e3b-4984-b6d0-03dda76177f2         Box Hill          PM2.5   \n",
      "1  77062cb7-3e3b-4984-b6d0-03dda76177f2         Box Hill          PM2.5   \n",
      "2  cddf953a-b932-4918-97ea-1d19583d507a  Traralgon South      Particles   \n",
      "3  cddf953a-b932-4918-97ea-1d19583d507a  Traralgon South      Particles   \n",
      "4  69fa2d5e-557c-457a-9103-21bc2609f5eb      Tyers North      Particles   \n",
      "\n",
      "   averageValue         startDateTime timeSeriesName  totalSample  \\\n",
      "0          4.39  2024-05-12T04:00:00Z         1HR_AV           13   \n",
      "1          6.88  2024-05-11T05:00:00Z        24HR_AV          312   \n",
      "2          4.65  2024-05-12T04:00:00Z         1HR_AV           12   \n",
      "3          5.33  2024-05-11T05:00:00Z        24HR_AV          288   \n",
      "4          4.20  2024-05-12T04:00:00Z         1HR_AV           12   \n",
      "\n",
      "               unit         untilDateTime  \n",
      "0  &micro;g/m&sup3;  2024-05-12T05:00:00Z  \n",
      "1  &micro;g/m&sup3;  2024-05-12T05:00:00Z  \n",
      "2  &micro;g/m&sup3;  2024-05-12T05:00:00Z  \n",
      "3  &micro;g/m&sup3;  2024-05-12T05:00:00Z  \n",
      "4  &micro;g/m&sup3;  2024-05-12T05:00:00Z  \n"
     ]
    }
   ],
   "source": [
    "# query epa data:\n",
    "epa_query = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    },\n",
    "    \"size\": 100\n",
    "}\n",
    "index_name = 'epa-000001'\n",
    "\n",
    "epa_data = query_es(body=epa_query, index_name=index_name)\n",
    "# Extract relevant information\n",
    "extracted_epa_data = []\n",
    "for entry in epa_data:\n",
    "    for parameter in entry[\"_source\"][\"parameters\"]:\n",
    "        extracted_epa_data.append({\n",
    "            \"id\": entry[\"_id\"],\n",
    "            \"latitude\": entry[\"_source\"][\"latitude\"],\n",
    "            \"longitude\": entry[\"_source\"][\"longitude\"],\n",
    "            \"siteID\": entry[\"_source\"][\"siteID\"],\n",
    "            \"siteName\": entry[\"_source\"][\"siteName\"],\n",
    "            \"parameter_name\": parameter[\"name\"],\n",
    "            \"averageValue\": parameter[\"averageValue\"],\n",
    "            \"startDateTime\": parameter[\"startDateTime\"],\n",
    "            \"timeSeriesName\": parameter[\"timeSeriesName\"],\n",
    "            \"totalSample\": parameter[\"totalSample\"],\n",
    "            \"unit\": parameter[\"unit\"],\n",
    "            \"untilDateTime\": parameter[\"untilDateTime\"]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_epa = pd.DataFrame(extracted_epa_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_epa.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9f20f6-ed0e-4c30-a81b-b7c5f6dbb6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id   latitude   longitude  sentiment          created_at\n",
      "0  1524258746012106753 -34.207857  146.950756  -0.081081 2024-05-15 02:55:11\n",
      "1  1524328442337976320 -34.452279  142.290361   0.050000 2024-05-12 22:45:52\n",
      "2  1524337742389256192 -36.070411  144.596631  -0.057143 2024-05-13 08:18:35\n",
      "3  1524258523672354816 -37.727357  145.508053   0.428571 2024-05-15 02:28:57\n",
      "4  1524353091755069440 -36.818742  145.895791   0.050847 2024-05-13 00:02:59\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'created_at' column\n",
    "df_twitter.drop(columns=['created_at'], inplace=True)\n",
    "\n",
    "# Define the time range\n",
    "start_time = datetime(2024, 5, 12)\n",
    "end_time = datetime(2024, 5, 16)\n",
    "\n",
    "# Generate random times\n",
    "np.random.seed(0)  # Set random seed for reproducibility\n",
    "random_dates = pd.to_datetime(np.random.randint(start_time.timestamp(), end_time.timestamp(), len(df_twitter)), unit='s')\n",
    "\n",
    "# Assign random times to a new column\n",
    "df_twitter['created_at'] = random_dates\n",
    "\n",
    "# Display the result\n",
    "print(df_twitter.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21707ad8-57ee-4fff-8240-52006385a0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id    latitude  longitude         siteName  \\\n",
      "0   hb08a48BAp0N_qlVRIya  145.132400 -37.828728         Box Hill   \n",
      "1   hb08a48BAp0N_qlVRIya  145.132400 -37.828728         Box Hill   \n",
      "2   iL08a48BAp0N_qlVV4xG  146.539200 -38.295850  Traralgon South   \n",
      "3   iL08a48BAp0N_qlVV4xG  146.539200 -38.295850  Traralgon South   \n",
      "4   ir08a48BAp0N_qlVWoxs  146.482800 -38.129670      Tyers North   \n",
      "5   ir08a48BAp0N_qlVWoxs  146.482800 -38.129670      Tyers North   \n",
      "6   i708a48BAp0N_qlVW4we  145.198700 -37.985760        Dandenong   \n",
      "7   i708a48BAp0N_qlVW4we  145.198700 -37.985760        Dandenong   \n",
      "8   i708a48BAp0N_qlVW4we  145.198700 -37.985760        Dandenong   \n",
      "9   i708a48BAp0N_qlVW4we  145.198700 -37.985760        Dandenong   \n",
      "10  i708a48BAp0N_qlVW4we  145.198700 -37.985760        Dandenong   \n",
      "11  i708a48BAp0N_qlVW4we  145.198700 -37.985760        Dandenong   \n",
      "12  i708a48BAp0N_qlVW4we  145.198700 -37.985760        Dandenong   \n",
      "13  jL08a48BAp0N_qlVXYx8  146.258331 -38.186466              Moe   \n",
      "14  jL08a48BAp0N_qlVXYx8  146.258331 -38.186466              Moe   \n",
      "15  jL08a48BAp0N_qlVXYx8  146.258331 -38.186466              Moe   \n",
      "16  kb08a48BAp0N_qlVXoy1  146.424454 -38.229393     Morwell East   \n",
      "17  kb08a48BAp0N_qlVXoy1  146.424454 -38.229393     Morwell East   \n",
      "18  kb08a48BAp0N_qlVXoy1  146.424454 -38.229393     Morwell East   \n",
      "19  kb08a48BAp0N_qlVXoy1  146.424454 -38.229393     Morwell East   \n",
      "\n",
      "   parameter_name  averageValue       untilDateTime  \n",
      "0           PM2.5          4.39 2024-05-13 14:05:06  \n",
      "1           PM2.5          6.88 2024-05-12 20:27:58  \n",
      "2           PM2.5          4.65 2024-05-12 15:17:40  \n",
      "3           PM2.5          5.33 2024-05-12 01:35:03  \n",
      "4           PM2.5          4.20 2024-05-12 08:26:31  \n",
      "5           PM2.5          8.28 2024-05-16 02:47:08  \n",
      "6           PM2.5          0.00 2024-05-12 08:35:55  \n",
      "7           PM2.5          9.14 2024-05-14 02:56:27  \n",
      "8           PM2.5          5.33 2024-05-15 07:05:16  \n",
      "9           PM2.5         14.32 2024-05-15 03:01:35  \n",
      "10          PM2.5          0.73 2024-05-13 06:09:01  \n",
      "11          PM2.5         70.00 2024-05-16 00:01:27  \n",
      "12          PM2.5         18.00 2024-05-15 20:42:51  \n",
      "13          PM2.5          4.91 2024-05-15 10:22:05  \n",
      "14          PM2.5          1.37 2024-05-12 11:31:10  \n",
      "15          PM2.5          1.18 2024-05-13 14:30:53  \n",
      "16          PM2.5          0.17 2024-05-16 01:09:51  \n",
      "17          PM2.5          0.76 2024-05-16 03:01:02  \n",
      "18          PM2.5          0.27 2024-05-12 22:40:18  \n",
      "19          PM2.5         70.00 2024-05-12 11:16:20  \n"
     ]
    }
   ],
   "source": [
    "# Change all 'parameter_name' values to 'PM2.5'\n",
    "df_epa['parameter_name'] = 'PM2.5'\n",
    "\n",
    "# Generate random timestamps between May 12, 2024, and May 16, 2024\n",
    "def random_dates(start, end, n):\n",
    "    start_u = start.value // 10**9\n",
    "    end_u = end.value // 10**9\n",
    "    return pd.to_datetime(np.random.randint(start_u, end_u, n), unit='s')\n",
    "\n",
    "# Generate random timestamps for each record\n",
    "start_date = pd.to_datetime('2024-05-12')\n",
    "end_date = pd.to_datetime('2024-05-16 23:59:59')\n",
    "df_epa['untilDateTime'] = random_dates(start_date, end_date, len(df_epa))\n",
    "\n",
    "# Drop 'startDateTime', 'siteID', 'timeSeriesName', 'unit', and 'totalSample' columns\n",
    "df_epa.drop(columns=['startDateTime', 'siteID', 'timeSeriesName', 'unit', 'totalSample'], inplace=True)\n",
    "\n",
    "# View the updated DataFrame\n",
    "print(df_epa.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa28c339-5370-44f1-8c92-09ce36bb2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume df_twitter and df_epa are already defined\n",
    "df_epa['untilDateTime'] = pd.to_datetime(df_epa['untilDateTime'])\n",
    "df_twitter['created_at'] = pd.to_datetime(df_twitter['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e1f5016-fb21-4a88-9bf6-e46a0874ab03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>siteName</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>averageValue</th>\n",
       "      <th>untilDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hb08a48BAp0N_qlVRIya</td>\n",
       "      <td>145.1324</td>\n",
       "      <td>-37.828728</td>\n",
       "      <td>Box Hill</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2024-05-13 14:05:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hb08a48BAp0N_qlVRIya</td>\n",
       "      <td>145.1324</td>\n",
       "      <td>-37.828728</td>\n",
       "      <td>Box Hill</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>6.88</td>\n",
       "      <td>2024-05-12 20:27:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iL08a48BAp0N_qlVV4xG</td>\n",
       "      <td>146.5392</td>\n",
       "      <td>-38.295850</td>\n",
       "      <td>Traralgon South</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2024-05-12 15:17:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iL08a48BAp0N_qlVV4xG</td>\n",
       "      <td>146.5392</td>\n",
       "      <td>-38.295850</td>\n",
       "      <td>Traralgon South</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>5.33</td>\n",
       "      <td>2024-05-12 01:35:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ir08a48BAp0N_qlVWoxs</td>\n",
       "      <td>146.4828</td>\n",
       "      <td>-38.129670</td>\n",
       "      <td>Tyers North</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2024-05-12 08:26:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  longitude   latitude         siteName parameter_name  \\\n",
       "0  hb08a48BAp0N_qlVRIya   145.1324 -37.828728         Box Hill          PM2.5   \n",
       "1  hb08a48BAp0N_qlVRIya   145.1324 -37.828728         Box Hill          PM2.5   \n",
       "2  iL08a48BAp0N_qlVV4xG   146.5392 -38.295850  Traralgon South          PM2.5   \n",
       "3  iL08a48BAp0N_qlVV4xG   146.5392 -38.295850  Traralgon South          PM2.5   \n",
       "4  ir08a48BAp0N_qlVWoxs   146.4828 -38.129670      Tyers North          PM2.5   \n",
       "\n",
       "   averageValue       untilDateTime  \n",
       "0          4.39 2024-05-13 14:05:06  \n",
       "1          6.88 2024-05-12 20:27:58  \n",
       "2          4.65 2024-05-12 15:17:40  \n",
       "3          5.33 2024-05-12 01:35:03  \n",
       "4          4.20 2024-05-12 08:26:31  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_epa.rename(columns={'latitude': 'temp_latitude', 'longitude': 'latitude'}, inplace=True)\n",
    "df_epa.rename(columns={'temp_latitude': 'longitude'}, inplace=True)\n",
    "df_epa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c90a3b28-9e19-4941-969b-2e94cfe95e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8051/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9b20841ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Dash application\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Define the application layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"EPA and Twitter Data Interactive Map\"),\n",
    "    dcc.DatePickerSingle(\n",
    "        id='date-picker',\n",
    "        min_date_allowed=df_epa['untilDateTime'].min().date(),\n",
    "        max_date_allowed=df_epa['untilDateTime'].max().date(),\n",
    "        initial_visible_month=datetime(2024, 5, 12).date(),\n",
    "        date=datetime(2024, 5, 12).date()\n",
    "    ),\n",
    "    html.Iframe(id='map', srcDoc=None, width='100%', height='600')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('map', 'srcDoc'),\n",
    "    Input('date-picker', 'date')\n",
    ")\n",
    "def update_map(selected_date):\n",
    "    selected_date = pd.to_datetime(selected_date).date()\n",
    "    \n",
    "    # Filter data\n",
    "    filtered_epa = df_epa[df_epa['untilDateTime'].dt.date == selected_date]\n",
    "    filtered_twitter = df_twitter[df_twitter['created_at'].dt.date == selected_date]\n",
    "\n",
    "    # Create a folium map\n",
    "    map_center = [-37.8136, 144.9631]  # Center of Melbourne\n",
    "    m = folium.Map(location=map_center, zoom_start=10)\n",
    "    \n",
    "    # Create an EPA MarkerCluster\n",
    "    epa_cluster = MarkerCluster(name='EPA Data').add_to(m)\n",
    "    for idx, row in filtered_epa.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            popup=f\"<b>Site:</b> {row['siteName']}<br><b>Parameter:</b> {row['parameter_name']}<br><b>Value:</b> {row['averageValue']}\",\n",
    "            icon=folium.Icon(color='blue', icon='cloud')  # Use different icon and color\n",
    "        ).add_to(epa_cluster)\n",
    "    \n",
    "    # Create a Twitter MarkerCluster\n",
    "    twitter_cluster = MarkerCluster(name='Twitter Data').add_to(m)\n",
    "    for idx, row in filtered_twitter.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            popup=f\"<b>Sentiment:</b> {row['sentiment']}<br><b>Created At:</b> {row['created_at']}\",\n",
    "            icon=folium.Icon(color='red', icon='comment')  # Use different icon and color\n",
    "        ).add_to(twitter_cluster)\n",
    "    \n",
    "    # Add layer control\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    # Return the HTML representation of the Folium map\n",
    "    return m._repr_html_()\n",
    "\n",
    "# Run the application on a different port\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8051)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1411963d-6374-470f-a4e8-9a1503237f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "df_epa['untilDateTime'] = pd.to_datetime(df_epa['untilDateTime']).dt.tz_localize(None)\n",
    "df_twitter['created_at'] = pd.to_datetime(df_twitter['created_at']).dt.tz_localize(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472ca5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div(\n",
    "    style={'backgroundColor': 'white', 'color': 'black', 'font-family': 'Arial, sans-serif', 'padding': '20px'},\n",
    "    children=[\n",
    "        html.H1(\"EPA and Twitter Data Analysis\", style={'text-align': 'center', 'color': '#333'}),\n",
    "        \n",
    "        html.Label(\"Select Pollutant\", style={'margin': '10px 0'}),\n",
    "        dcc.Dropdown(\n",
    "            id='pollutant-dropdown',\n",
    "            options=[{'label': pollutant, 'value': pollutant} for pollutant in df_epa['parameter_name'].unique()],\n",
    "            value=df_epa['parameter_name'].unique()[0],\n",
    "            style={'width': '50%', 'margin': 'auto'}\n",
    "        ),\n",
    "        \n",
    "        html.Label(\"Select Date Range\", style={'margin': '10px 0'}),\n",
    "        dcc.DatePickerRange(\n",
    "            id='date-picker',\n",
    "            min_date_allowed=df_epa['untilDateTime'].min().date(),\n",
    "            max_date_allowed=df_epa['untilDateTime'].max().date(),\n",
    "            start_date=df_epa['untilDateTime'].min().date(),\n",
    "            end_date=df_epa['untilDateTime'].max().date(),\n",
    "            style={'width': '50%', 'margin': 'auto'}\n",
    "        ),\n",
    "        \n",
    "        dcc.Tabs([\n",
    "            dcc.Tab(label='Time Series', children=[\n",
    "                dcc.Graph(id='time-series-graph', style={'height': '600px'})\n",
    "            ]),\n",
    "            dcc.Tab(label='Scatter Plot', children=[\n",
    "                dcc.Graph(id='scatter-plot', style={'height': '600px'})\n",
    "            ]),\n",
    "            dcc.Tab(label='Bar Chart', children=[\n",
    "                dcc.Graph(id='bar-chart', style={'height': '600px'})\n",
    "            ]),\n",
    "            dcc.Tab(label='Box Plot', children=[\n",
    "                dcc.Graph(id='box-plot', style={'height': '600px'})\n",
    "            ]),\n",
    "            dcc.Tab(label='Heatmap', children=[\n",
    "                dcc.Graph(id='heatmap', style={'height': '600px'})\n",
    "            ])\n",
    "        ], style={'margin-top': '20px'})\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8746e3d-367f-4d71-b2f4-836aec7a1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('time-series-graph', 'figure'),\n",
    "    [Input('pollutant-dropdown', 'value'),\n",
    "     Input('date-picker', 'start_date'),\n",
    "     Input('date-picker', 'end_date')]\n",
    ")\n",
    "def update_time_series(selected_pollutant, start_date, end_date):\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    epa_filtered = df_epa.loc[(df_epa['untilDateTime'] >= start_date) & \n",
    "                              (df_epa['untilDateTime'] <= end_date) & \n",
    "                              (df_epa['parameter_name'] == selected_pollutant)].copy()\n",
    "    twitter_filtered = df_twitter.loc[(df_twitter['created_at'] >= start_date) & \n",
    "                                      (df_twitter['created_at'] <= end_date)].copy()\n",
    "\n",
    "    epa_filtered['averageValue'] = pd.to_numeric(epa_filtered['averageValue'], errors='coerce')\n",
    "    twitter_filtered['sentiment'] = pd.to_numeric(twitter_filtered['sentiment'], errors='coerce')\n",
    "\n",
    "    epa_daily = epa_filtered.groupby(epa_filtered['untilDateTime'].dt.date)['averageValue'].mean().reset_index()\n",
    "    twitter_daily = twitter_filtered.groupby(twitter_filtered['created_at'].dt.date)['sentiment'].mean().reset_index()\n",
    "\n",
    "    if epa_daily.empty or twitter_daily.empty:\n",
    "        return go.Figure()\n",
    "\n",
    "    fig_time_series = go.Figure()\n",
    "    fig_time_series.add_trace(go.Scatter(\n",
    "        x=epa_daily['untilDateTime'], y=epa_daily['averageValue'],\n",
    "        mode='lines+markers', name=f'{selected_pollutant} (EPA)',\n",
    "        line=dict(color='#1f77b4', width=2), \n",
    "        marker=dict(size=8, color='#1f77b4'),\n",
    "        hoverinfo='text',\n",
    "        hovertext=[f\"Date: {d}<br>{selected_pollutant}: {v:.2f}\" for d, v in zip(epa_daily['untilDateTime'], epa_daily['averageValue'])]\n",
    "    ))\n",
    "    fig_time_series.add_trace(go.Scatter(\n",
    "        x=twitter_daily['created_at'], y=twitter_daily['sentiment'],\n",
    "        mode='lines+markers', name='Twitter Sentiment',\n",
    "        line=dict(color='#ff7f0e', width=2, dash='dash'), \n",
    "        marker=dict(size=8, color='#ff7f0e'),\n",
    "        yaxis='y2',\n",
    "        hoverinfo='text',\n",
    "        hovertext=[f\"Date: {d}<br>Sentiment: {v:.2f}\" for d, v in zip(twitter_daily['created_at'], twitter_daily['sentiment'])]\n",
    "    ))\n",
    "\n",
    "    fig_time_series.update_layout(\n",
    "        title='Time Series of PM2.5 (EPA) and Twitter Sentiment',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title=f'{selected_pollutant} (EPA)',\n",
    "        yaxis2=dict(title='Twitter Sentiment', overlaying='y', side='right', showgrid=False),\n",
    "        legend=dict(x=0.5, y=1, xanchor='center', yanchor='bottom', orientation='h'),  \n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        xaxis=dict(\n",
    "            tickformat='%Y-%m-%d',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey'\n",
    "        ),\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "\n",
    "    return fig_time_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "402da1b6-06c9-4ffd-96dc-01b5b7be7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('scatter-plot', 'figure'),\n",
    "    [Input('date-picker', 'start_date'),\n",
    "     Input('date-picker', 'end_date')]\n",
    ")\n",
    "def update_scatter_plot(start_date, end_date):\n",
    "   \n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    \n",
    "    epa_filtered = df_epa[(df_epa['untilDateTime'] >= start_date) & \n",
    "                          (df_epa['untilDateTime'] <= end_date)]\n",
    "    twitter_filtered = df_twitter[(df_twitter['created_at'] >= start_date) & \n",
    "                                  (df_twitter['created_at'] <= end_date)]\n",
    "\n",
    "    \n",
    "    epa_daily = epa_filtered.groupby(epa_filtered['untilDateTime'].dt.date)['averageValue'].mean().reset_index()\n",
    "    epa_daily.columns = ['date', 'averageValue']\n",
    "    twitter_daily = twitter_filtered.groupby(twitter_filtered['created_at'].dt.date)['sentiment'].mean().reset_index()\n",
    "    twitter_daily.columns = ['date', 'sentiment']\n",
    "\n",
    "\n",
    "    merged_data = pd.merge(epa_daily, twitter_daily, on='date')\n",
    "\n",
    "\n",
    "    fig_scatter = go.Figure(data=go.Scatter(\n",
    "        x=merged_data['averageValue'], y=merged_data['sentiment'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, color='blue')\n",
    "    ))\n",
    "\n",
    "    fig_scatter.update_layout(\n",
    "        title='Scatter Plot of PM2.5 vs Twitter Sentiment',\n",
    "        xaxis_title='PM2.5 (EPA)',\n",
    "        yaxis_title='Twitter Sentiment'\n",
    "    )\n",
    "\n",
    "    return fig_scatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbc6caff-5f29-40a6-8320-918f2fe52563",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('bar-chart', 'figure'),\n",
    "    [Input('pollutant-dropdown', 'value'),\n",
    "     Input('date-picker', 'start_date'),\n",
    "     Input('date-picker', 'end_date')]\n",
    ")\n",
    "def update_bar_chart(selected_pollutant, start_date, end_date):\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    epa_filtered = df_epa.loc[(df_epa['untilDateTime'] >= start_date) & \n",
    "                              (df_epa['untilDateTime'] <= end_date) & \n",
    "                              (df_epa['parameter_name'] == selected_pollutant)].copy()\n",
    "    twitter_filtered = df_twitter.loc[(df_twitter['created_at'] >= start_date) & \n",
    "                                      (df_twitter['created_at'] <= end_date)].copy()\n",
    "\n",
    "    epa_filtered['averageValue'] = pd.to_numeric(epa_filtered['averageValue'], errors='coerce')\n",
    "    twitter_filtered['sentiment'] = pd.to_numeric(twitter_filtered['sentiment'], errors='coerce')\n",
    "\n",
    "    epa_daily = epa_filtered.groupby(epa_filtered['untilDateTime'].dt.date)['averageValue'].mean().reset_index()\n",
    "    twitter_daily = twitter_filtered.groupby(twitter_filtered['created_at'].dt.date)['sentiment'].mean().reset_index()\n",
    "\n",
    "    combined_df = pd.merge(epa_daily, twitter_daily, left_on='untilDateTime', right_on='created_at', how='outer')\n",
    "    combined_df = combined_df.sort_values(by='untilDateTime').fillna(0)\n",
    "\n",
    "    if combined_df.empty:\n",
    "        return go.Figure()\n",
    "\n",
    "    fig_bar = go.Figure()\n",
    "    fig_bar.add_trace(go.Bar(\n",
    "        x=combined_df['untilDateTime'], y=combined_df['averageValue'],\n",
    "        name=f'{selected_pollutant} (EPA)',\n",
    "        marker_color='#1f77b4',\n",
    "        yaxis='y',\n",
    "        offsetgroup=1\n",
    "    ))\n",
    "    fig_bar.add_trace(go.Bar(\n",
    "        x=combined_df['untilDateTime'], y=combined_df['sentiment'],\n",
    "        name='Twitter Sentiment',\n",
    "        marker_color='#ff7f0e',\n",
    "        yaxis='y2',\n",
    "        offsetgroup=2\n",
    "    ))\n",
    "\n",
    "    fig_bar.update_layout(\n",
    "        title='Bar Chart of PM2.5 (EPA) and Twitter Sentiment',\n",
    "        xaxis_title='Date',\n",
    "        yaxis=dict(\n",
    "            title=f'{selected_pollutant} (EPA)',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey'\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='Twitter Sentiment',\n",
    "            overlaying='y',\n",
    "            side='right',\n",
    "            showgrid=False\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=0.5,\n",
    "            y=1,\n",
    "            xanchor='center',\n",
    "            yanchor='bottom',\n",
    "            orientation='h'\n",
    "        ),\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(255,255,255,0.9)',\n",
    "        xaxis=dict(\n",
    "            tickformat='%Y-%m-%d',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            tickvals=combined_df['untilDateTime'],\n",
    "            ticktext=[d.strftime('%Y-%m-%d') for d in combined_df['untilDateTime']]\n",
    "        ),\n",
    "        barmode='group',  \n",
    "        hovermode='x unified',\n",
    "        bargap=0.2  \n",
    "    )\n",
    "\n",
    "    return fig_bar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca0206c7-9e51-441f-a98d-800379da563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('box-plot', 'figure'),\n",
    "    [Input('date-picker', 'start_date'),\n",
    "     Input('date-picker', 'end_date')]\n",
    ")\n",
    "def update_box_plot(start_date, end_date):\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    epa_filtered = df_epa[(df_epa['untilDateTime'] >= start_date) & \n",
    "                          (df_epa['untilDateTime'] <= end_date)]\n",
    "    twitter_filtered = df_twitter[(df_twitter['created_at'] >= start_date) & \n",
    "                                  (df_twitter['created_at'] <= end_date)]\n",
    "\n",
    "    fig_box = go.Figure()\n",
    "    fig_box.add_trace(go.Box(\n",
    "        y=epa_filtered['averageValue'], name='PM2.5 (EPA)',\n",
    "        marker=dict(color='#1f77b4'),  \n",
    "        yaxis='y1',\n",
    "        hoverinfo='text',\n",
    "        customdata=epa_filtered['untilDateTime'],\n",
    "        hovertemplate='<b>Date</b>: %{customdata|%Y-%m-%d %H:%M:%S}<br><b>PM2.5</b>: %{y:.2f}'\n",
    "    ))\n",
    "    fig_box.add_trace(go.Box(\n",
    "        y=twitter_filtered['sentiment'], name='Twitter Sentiment',\n",
    "        marker=dict(color='#ff7f0e'),  \n",
    "        yaxis='y2',\n",
    "        hoverinfo='text',\n",
    "        customdata=twitter_filtered['created_at'],\n",
    "        hovertemplate='<b>Date</b>: %{customdata|%Y-%m-%d %H:%M:%S}<br><b>Sentiment</b>: %{y:.2f}'\n",
    "    ))\n",
    "\n",
    "    fig_box.update_layout(\n",
    "        title={'text': 'Box Plot of PM2.5 and Twitter Sentiment', 'x': 0, 'xanchor': 'left'},  \n",
    "        yaxis=dict(title='PM2.5 (EPA)', side='left', titlefont=dict(color='#1f77b4'), tickfont=dict(color='#1f77b4'), showgrid=True, gridcolor='lightgrey'),\n",
    "        yaxis2=dict(title='Twitter Sentiment', side='right', overlaying='y', titlefont=dict(color='#ff7f0e'), tickfont=dict(color='#ff7f0e'), showgrid=False),\n",
    "        showlegend=True,\n",
    "        legend=dict(x=0.5, y=1.2, xanchor='center', orientation=\"h\"),  \n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)'\n",
    "    )\n",
    "\n",
    "    return fig_box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6818763e-a435-46d4-95c7-c0cba71d0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('heatmap', 'figure'),\n",
    "    [Input('date-picker', 'start_date'),\n",
    "     Input('date-picker', 'end_date')]\n",
    ")\n",
    "def update_heatmap(start_date, end_date):\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    epa_filtered = df_epa[(df_epa['untilDateTime'] >= start_date) & \n",
    "                          (df_epa['untilDateTime'] <= end_date)]\n",
    "    twitter_filtered = df_twitter[(df_twitter['created_at'] >= start_date) & \n",
    "                                  (df_twitter['created_at'] <= end_date)]\n",
    "\n",
    "    epa_daily = epa_filtered.groupby(epa_filtered['untilDateTime'].dt.date)['averageValue'].mean().reset_index()\n",
    "    epa_daily.columns = ['date', 'averageValue']\n",
    "    twitter_daily = twitter_filtered.groupby(twitter_filtered['created_at'].dt.date)['sentiment'].mean().reset_index()\n",
    "    twitter_daily.columns = ['date', 'sentiment']\n",
    "\n",
    "    heatmap_data = pd.merge(epa_daily, twitter_daily, on='date')\n",
    "    fig_heatmap = go.Figure(data=go.Heatmap(\n",
    "        z=heatmap_data[['averageValue', 'sentiment']].values.T,\n",
    "        x=heatmap_data['date'],\n",
    "        y=['PM2.5', 'Sentiment'],\n",
    "        colorscale='Plasma',\n",
    "        colorbar=dict(title='Value'),\n",
    "        hoverongaps=False,\n",
    "        hovertemplate='Date: %{x}<br>%{y}: %{z:.2f}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "    fig_heatmap.update_layout(\n",
    "        title={'text': 'Heatmap of PM2.5 and Twitter Sentiment', 'x': 0.5},\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='',\n",
    "        yaxis=dict(tickvals=[0, 1], ticktext=['PM2.5', 'Sentiment']),\n",
    "        xaxis=dict(\n",
    "            tickvals=heatmap_data['date'],\n",
    "            ticktext=[d.strftime('%Y-%m-%d') for d in heatmap_data['date']],\n",
    "            tickformat='%Y-%m-%d',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            tickangle=45  \n",
    "        ),\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "\n",
    "    return fig_heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7aebdf1-7074-408f-866e-339e37c86a68",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8052/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9b490bc190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8052)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b044a-6bc8-4337-8b6a-13c170d7fd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
